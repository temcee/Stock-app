import streamlit as st
import yfinance as yf
import pandas as pd
import time
import json
import gspread
import requests
import io
from datetime import date
from google.oauth2.service_account import Credentials
from yfinance.exceptions import YFRateLimitError

# --------------------
# åˆæœŸè¨­å®š
# --------------------
st.set_page_config(layout="wide")
st.title("ğŸ“ˆ æ ªå¼éŠ˜æŸ„ç®¡ç†ãƒ„ãƒ¼ãƒ«")

SPREADSHEET_ID = "1noyNkmaeisqi96_xAFS-yo18pqtcWOu8yOpDzzOKnhg"
SHEET_WATCH    = "ã‚·ãƒ¼ãƒˆ1"
SHEET_HOLDINGS = "holdings"
SHEET_HISTORY  = "asset_history"

WATCH_COLS    = ["ã‚³ãƒ¼ãƒ‰", "éŠ˜æŸ„å", "æ ªä¾¡", "PER", "PBR", "ROE", "é…å½“",
                 "å››å­£å ±", "ã‚¿ã‚°", "ãƒ¡ãƒ¢", "ç›®æ¨™æ ªä¾¡", "å‰Šé™¤"]
HOLDING_COLS  = ["ã‚³ãƒ¼ãƒ‰", "éŠ˜æŸ„å", "å–å¾—å˜ä¾¡", "æšæ•°"]
HISTORY_COLS  = ["æ—¥ä»˜", "ç·è³‡ç”£", "æç›Šåˆè¨ˆ", "ãƒ«ãƒƒã‚¯ã‚¹ãƒ«ãƒ¼åˆ©ç›Š"]

# --------------------
# æ±è¨¼éŠ˜æŸ„åãƒã‚¹ã‚¿
# --------------------
@st.cache_data(ttl=86400)
def load_tse_master():
    try:
        url = "https://www.jpx.co.jp/markets/statistics-equities/misc/tvdivq0000001vg2-att/data_j.xls"
        r = requests.get(url, timeout=10)
        xls = pd.read_excel(io.BytesIO(r.content), header=0)
        code_col = [c for c in xls.columns if "ã‚³ãƒ¼ãƒ‰" in str(c)][0]
        name_col = [c for c in xls.columns if "éŠ˜æŸ„å" in str(c)][0]
        return dict(zip(xls[code_col].astype(str).str.zfill(4), xls[name_col]))
    except Exception:
        return {}

# --------------------
# Google Sheetsæ¥ç¶š
# --------------------
def get_spreadsheet():
    creds_dict = json.loads(st.secrets["GOOGLE_SERVICE_ACCOUNT"])
    creds = Credentials.from_service_account_info(
        creds_dict,
        scopes=[
            "https://www.googleapis.com/auth/spreadsheets",
            "https://www.googleapis.com/auth/drive"
        ]
    )
    client = gspread.authorize(creds)
    return client.open_by_key(SPREADSHEET_ID)

def get_or_create_sheet(spreadsheet, name, columns):
    try:
        return spreadsheet.worksheet(name)
    except gspread.WorksheetNotFound:
        sheet = spreadsheet.add_worksheet(title=name, rows=1000, cols=20)
        sheet.append_row(columns)
        return sheet

def load_df(sheet, columns):
    values = sheet.get_all_values()
    if len(values) <= 1:
        return pd.DataFrame(columns=columns)
    headers = values[0]
    rows = values[1:]
    df = pd.DataFrame(rows, columns=headers)
    if "å‰Šé™¤" in df.columns:
        df["å‰Šé™¤"] = df["å‰Šé™¤"].apply(lambda x: str(x).upper() == "TRUE")
    return df

def save_df(sheet, df):
    save = df.copy()
    save = save.fillna("")
    for col in save.columns:
        if col != "å‰Šé™¤":
            save[col] = save[col].apply(
                lambda x: int(x) if isinstance(x, float) and not pd.isna(x) and x == int(x) else x
            )
    if "å‰Šé™¤" in save.columns:
        save["å‰Šé™¤"] = save["å‰Šé™¤"].apply(
            lambda x: "TRUE" if x is True or str(x).upper() == "TRUE" else "FALSE"
        )
    sheet.clear()
    sheet.update([save.columns.tolist()] + save.values.tolist())

# --------------------
# å…±é€šé–¢æ•°
# --------------------
@st.cache_data(ttl=3600)
def fetch_stock_data(code):
    try:
        time.sleep(1)
        ticker = yf.Ticker(code)
        info = ticker.info
        name = info.get("longName") or info.get("shortName") or ""
        if code.endswith(".T"):
            raw = code.replace(".T", "").zfill(4)
            jp_name = load_tse_master().get(raw, "")
            if jp_name:
                name = jp_name
        price = info.get("currentPrice")
        per   = info.get("trailingPE")
        pbr   = info.get("priceToBook")
        roe   = info.get("returnOnEquity")
        if roe is not None:
            roe *= 100
        div = info.get("dividendYield")
        eps = info.get("trailingEps")
        return name, price, per, pbr, roe, div, eps
    except YFRateLimitError:
        return "", None, None, None, None, None, None
    except Exception:
        return "", None, None, None, None, None, None

def normalize_tags(tag_str):
    if not isinstance(tag_str, str):
        return ""
    return " ".join(tag_str.replace("ã€€", " ").split())

def normalize_code(code):
    code = str(code).strip().upper()
    if "." in code:
        return code
    if len(code) <= 5:
        return f"{code}.T"
    return code

def get_ir_links(code):
    raw = code.upper().replace(".T", "").strip()
    return (f"https://ir-searcher.com/kobetsu.php?code={raw}",
            f"https://irbank.net/{raw}")

def format_watch_df(df):
    view = df.copy()
    for col in ["æ ªä¾¡", "PER", "PBR", "ROE", "é…å½“"]:
        if col in view.columns:
            view[col] = pd.to_numeric(view[col], errors="coerce")
    view["æ ªä¾¡"]   = view["æ ªä¾¡"].round(0)
    view["PER"]    = view["PER"].round(1)
    view["PBR"]    = view["PBR"].round(1)
    view["ROE(%)"] = view["ROE"].round(1)
    if "é…å½“" in view.columns:
        view["é…å½“"] = view["é…å½“"].round(2)
    view["IR Searcher"] = view["ã‚³ãƒ¼ãƒ‰"].apply(lambda c: get_ir_links(c)[0])
    view["irbank"]      = view["ã‚³ãƒ¼ãƒ‰"].apply(lambda c: get_ir_links(c)[1])
    view.drop(columns=["ROE"], inplace=True)
    col_order = ["ã‚³ãƒ¼ãƒ‰", "éŠ˜æŸ„å", "æ ªä¾¡", "PER", "PBR", "ROE(%)", "é…å½“",
                 "å››å­£å ±", "ç›®æ¨™æ ªä¾¡", "ã‚¿ã‚°", "ãƒ¡ãƒ¢", "IR Searcher", "irbank", "å‰Šé™¤"]
    return view[[c for c in col_order if c in view.columns]]

def get_all_tags(df):
    tags = set()
    for t in df["ã‚¿ã‚°"]:
        if isinstance(t, str):
            tags.update(t.split())
    return sorted(tags)

# --------------------
# ã‚·ãƒ¼ãƒˆæ¥ç¶š
# --------------------
spreadsheet   = get_spreadsheet()
watch_sheet   = get_or_create_sheet(spreadsheet, SHEET_WATCH,    WATCH_COLS)
holding_sheet = get_or_create_sheet(spreadsheet, SHEET_HOLDINGS, HOLDING_COLS)
history_sheet = get_or_create_sheet(spreadsheet, SHEET_HISTORY,  HISTORY_COLS)

# --------------------
# ã‚¿ãƒ–
# --------------------
tab1, tab2 = st.tabs(["ğŸ“‹ ã‚¦ã‚©ãƒƒãƒãƒªã‚¹ãƒˆ", "ğŸ’¼ ä¿æœ‰æ ª"])

# ====================
# TAB1: ã‚¦ã‚©ãƒƒãƒãƒªã‚¹ãƒˆ
# ====================
with tab1:
    watch_df = load_df(watch_sheet, WATCH_COLS)

    defaults = {"éŠ˜æŸ„å": "", "å››å­£å ±": 0, "é…å½“": None,
                "ã‚¿ã‚°": "", "ãƒ¡ãƒ¢": "", "ç›®æ¨™æ ªä¾¡": None, "å‰Šé™¤": False}
    for col, val in defaults.items():
        if col not in watch_df.columns:
            watch_df[col] = val
    for col in ["ã‚¿ã‚°", "ãƒ¡ãƒ¢", "éŠ˜æŸ„å"]:
        watch_df[col] = watch_df[col].astype(str).fillna("")

    # éŠ˜æŸ„è¿½åŠ 
    st.subheader("â• éŠ˜æŸ„ã‚’è¿½åŠ ")
    raw_code = st.text_input("éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ï¼ˆä¾‹ï¼š7203 / AAPLï¼‰")
    code = normalize_code(raw_code)

    if st.button("éŠ˜æŸ„ã‚’è¿½åŠ "):
        name, price, per, pbr, roe, div, _ = fetch_stock_data(code)
        if code in watch_df["ã‚³ãƒ¼ãƒ‰"].values:
            watch_df.loc[watch_df["ã‚³ãƒ¼ãƒ‰"] == code, "å››å­£å ±"] += 1
            if name:
                watch_df.loc[watch_df["ã‚³ãƒ¼ãƒ‰"] == code, "éŠ˜æŸ„å"] = name
            st.info("æ—¢å­˜éŠ˜æŸ„ã®ãŸã‚ã€å››å­£å ±ã‚’ +1 ã—ã¾ã—ãŸ")
        else:
            watch_df = pd.concat([watch_df, pd.DataFrame([{
                "ã‚³ãƒ¼ãƒ‰": code, "éŠ˜æŸ„å": name, "æ ªä¾¡": price,
                "PER": per, "PBR": pbr, "ROE": roe, "é…å½“": div,
                "å››å­£å ±": 1, "ã‚¿ã‚°": "", "ãƒ¡ãƒ¢": "", "ç›®æ¨™æ ªä¾¡": None, "å‰Šé™¤": False
            }])], ignore_index=True)
            st.success("è¿½åŠ ã—ã¾ã—ãŸ")
        save_df(watch_sheet, watch_df)
        st.rerun()

    st.divider()

    # CSVè¿½åŠ 
    st.subheader("ğŸ“‚ CSVã‹ã‚‰éŠ˜æŸ„ã‚’è¿½åŠ ")
    uploaded_file = st.file_uploader("codeåˆ—ã‚’æŒã¤CSV", type="csv")
    if uploaded_file:
        add_df = pd.read_csv(uploaded_file)
        if "code" not in add_df.columns and "ã‚³ãƒ¼ãƒ‰" not in add_df.columns:
            st.error("CSVã« code åˆ—ã¾ãŸã¯ ã‚³ãƒ¼ãƒ‰ åˆ—ãŒã‚ã‚Šã¾ã›ã‚“")
        else:
            code_col = "code" if "code" in add_df.columns else "ã‚³ãƒ¼ãƒ‰"
            for rc in add_df[code_col]:
                c = normalize_code(rc)
                if c not in watch_df["ã‚³ãƒ¼ãƒ‰"].values:
                    name, price, per, pbr, roe, div, _ = fetch_stock_data(c)
                    watch_df = pd.concat([watch_df, pd.DataFrame([{
                        "ã‚³ãƒ¼ãƒ‰": c, "éŠ˜æŸ„å": name, "æ ªä¾¡": price,
                        "PER": per, "PBR": pbr, "ROE": roe, "é…å½“": div,
                        "å››å­£å ±": 1, "ã‚¿ã‚°": "", "ãƒ¡ãƒ¢": "", "ç›®æ¨™æ ªä¾¡": None, "å‰Šé™¤": False
                    }])], ignore_index=True)
            save_df(watch_sheet, watch_df)
            st.success("CSVè¿½åŠ å®Œäº†")

    st.divider()

    # ä¸€è¦§è¡¨ç¤º
    st.subheader("ğŸ“Š ç™»éŒ²éŠ˜æŸ„ä¸€è¦§")
    sort_col  = st.selectbox("ä¸¦ã³æ›¿ãˆ", ["æ ªä¾¡", "PER", "PBR", "ROE(%)", "é…å½“"])
    ascending = st.checkbox("æ˜‡é †", False)

    for col in ["æ ªä¾¡", "PER", "PBR", "ROE", "é…å½“"]:
        if col in watch_df.columns:
            watch_df[col] = pd.to_numeric(watch_df[col], errors="coerce")

    watch_df = watch_df.sort_values(
        by="ROE" if sort_col == "ROE(%)" else sort_col,
        ascending=ascending, na_position="last"
    )

    view_df = format_watch_df(watch_df)
    edited_df = st.data_editor(
        view_df, use_container_width=True,
        column_config={
            "ã‚¿ã‚°": st.column_config.TextColumn(help="ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šã§è¤‡æ•°æŒ‡å®š"),
            "ãƒ¡ãƒ¢": st.column_config.TextColumn(width="large"),
            "IR Searcher": st.column_config.LinkColumn(display_text="ğŸ” IR Searcher", disabled=True),
            "irbank":       st.column_config.LinkColumn(display_text="ğŸ“Š irbank",       disabled=True),
        }
    )
    edited_df["ROE"] = edited_df["ROE(%)"]
    edited_df.drop(columns=["ROE(%)", "IR Searcher", "irbank"], inplace=True)

    st.subheader("ğŸ·ï¸ ã‚¿ã‚°ã§çµã‚Šè¾¼ã¿")
    all_tags      = get_all_tags(watch_df)
    selected_tags = st.multiselect("ã‚¿ã‚°ã‚’é¸æŠ", all_tags)
    if selected_tags:
        watch_df = watch_df[watch_df["ã‚¿ã‚°"].apply(
            lambda x: all(tag in x.split() for tag in selected_tags)
        )]

    col1, col2, col3, col4 = st.columns(4)
    with col1:
        if st.button("ç·¨é›†å†…å®¹ã‚’ä¿å­˜"):
            edited_df["ã‚¿ã‚°"] = edited_df["ã‚¿ã‚°"].apply(normalize_tags)
            save_df(watch_sheet, edited_df)
            st.success("ä¿å­˜ã—ã¾ã—ãŸ")
            st.rerun()
    with col2:
        if st.button("é¸æŠã—ãŸéŠ˜æŸ„ã‚’å‰Šé™¤"):
            save_df(watch_sheet, edited_df[edited_df["å‰Šé™¤"] != True].assign(å‰Šé™¤=False))
            st.success("å‰Šé™¤ã—ã¾ã—ãŸ")
            st.rerun()
    with col3:
        if st.button("å…¨éŠ˜æŸ„ã‚’æ›´æ–°"):
            for i, row in watch_df.iterrows():
                name, price, per, pbr, roe, div, _ = fetch_stock_data(row["ã‚³ãƒ¼ãƒ‰"])
                if name:
                    watch_df.loc[i, "éŠ˜æŸ„å"] = name
                watch_df.loc[i, ["æ ªä¾¡", "PER", "PBR", "ROE", "é…å½“"]] = [price, per, pbr, roe, div]
            save_df(watch_sheet, watch_df)
            st.success("æ›´æ–°ã—ã¾ã—ãŸ")
    with col4:
        if st.button("éŠ˜æŸ„åã‚’æ—¥æœ¬èªã«æ›´æ–°"):
            master = load_tse_master()
            for i, row in watch_df.iterrows():
                if row["ã‚³ãƒ¼ãƒ‰"].endswith(".T"):
                    jp = master.get(row["ã‚³ãƒ¼ãƒ‰"].replace(".T", "").zfill(4), "")
                    if jp:
                        watch_df.loc[i, "éŠ˜æŸ„å"] = jp
            save_df(watch_sheet, watch_df)
            st.success("æ—¥æœ¬èªéŠ˜æŸ„åã«æ›´æ–°ã—ã¾ã—ãŸ")
            st.rerun()

# ====================
# TAB2: ä¿æœ‰æ ª
# ====================
with tab2:
    holding_df = load_df(holding_sheet, HOLDING_COLS)
    history_df = load_df(history_sheet, HISTORY_COLS)

    # ã‚³ãƒ¼ãƒ‰ã‚’æ­£è¦åŒ–ï¼ˆ.Tä»˜ä¸ï¼‰
    if "ã‚³ãƒ¼ãƒ‰" in holding_df.columns:
        holding_df["ã‚³ãƒ¼ãƒ‰"] = holding_df["ã‚³ãƒ¼ãƒ‰"].apply(normalize_code)

    for col in ["å–å¾—å˜ä¾¡", "æšæ•°"]:
        if col in holding_df.columns:
            holding_df[col] = pd.to_numeric(holding_df[col], errors="coerce")

    # ----------
    # æ ªä¾¡ãƒ»æŒ‡æ¨™ãƒ»éŠ˜æŸ„åã‚’å–å¾—ã—ã¦DataFrameã«çµåˆ
    # ----------
    names, prices, pers, pbrs, roes, epss = {}, {}, {}, {}, {}, {}
    for _, row in holding_df.iterrows():
        c = row["ã‚³ãƒ¼ãƒ‰"]
        name, price, per, pbr, roe, _, eps = fetch_stock_data(c)
        names[c]  = name or row.get("éŠ˜æŸ„å", "")
        prices[c] = price or 0
        pers[c]   = per
        pbrs[c]   = pbr
        roes[c]   = roe
        epss[c]   = eps or 0

    holding_df["éŠ˜æŸ„å"] = holding_df["ã‚³ãƒ¼ãƒ‰"].map(names)
    holding_df["æ ªä¾¡"]   = holding_df["ã‚³ãƒ¼ãƒ‰"].map(prices)
    holding_df["PER"]    = holding_df["ã‚³ãƒ¼ãƒ‰"].map(pers)
    holding_df["PBR"]    = holding_df["ã‚³ãƒ¼ãƒ‰"].map(pbrs)
    holding_df["ROE(%)"] = holding_df["ã‚³ãƒ¼ãƒ‰"].map(roes)
    holding_df["æ™‚ä¾¡"]   = holding_df["æ ªä¾¡"] * holding_df["æšæ•°"]
    holding_df["æç›Š"]   = (holding_df["æ ªä¾¡"] - holding_df["å–å¾—å˜ä¾¡"]) * holding_df["æšæ•°"]
    holding_df["EPS"]    = holding_df["ã‚³ãƒ¼ãƒ‰"].map(epss)
    holding_df["ãƒ«ãƒƒã‚¯ã‚¹ãƒ«ãƒ¼åˆ©ç›Š"] = holding_df["EPS"] * holding_df["æšæ•°"]

    # ----------
    # ã‚µãƒãƒªãƒ¼
    # ----------
    total_asset    = holding_df["æ™‚ä¾¡"].sum()
    total_pnl      = holding_df["æç›Š"].sum()
    total_lt       = holding_df["ãƒ«ãƒƒã‚¯ã‚¹ãƒ«ãƒ¼åˆ©ç›Š"].sum()

    st.subheader("ğŸ“Š ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚µãƒãƒªãƒ¼")
    c1, c2, c3 = st.columns(3)
    c1.metric("ç·è³‡ç”£ï¼ˆæ™‚ä¾¡åˆè¨ˆï¼‰", f"Â¥{total_asset:,.0f}")
    c2.metric("æç›Šåˆè¨ˆ",           f"Â¥{total_pnl:,.0f}")
    c3.metric("ãƒ«ãƒƒã‚¯ã‚¹ãƒ«ãƒ¼åˆ©ç›Š",   f"Â¥{total_lt:,.0f}")

    # ----------
    # ç·è³‡ç”£ã®è‡ªå‹•è¨˜éŒ²ï¼ˆå½“æ—¥åˆ†ãŒãªã‘ã‚Œã°è¨˜éŒ²ï¼‰
    # ----------
    today_str = date.today().isoformat()
    history_df["æ—¥ä»˜"] = history_df["æ—¥ä»˜"].astype(str)
    if today_str not in history_df["æ—¥ä»˜"].values and total_asset > 0:
        new_row = pd.DataFrame([{
            "æ—¥ä»˜": today_str,
            "ç·è³‡ç”£": round(total_asset, 0),
            "æç›Šåˆè¨ˆ": round(total_pnl, 0),
            "ãƒ«ãƒƒã‚¯ã‚¹ãƒ«ãƒ¼åˆ©ç›Š": round(total_lt, 0)
        }])
        history_df = pd.concat([history_df, new_row], ignore_index=True)
        save_df(history_sheet, history_df)

    st.divider()

    # ----------
    # ä¿æœ‰æ ªä¸€è¦§
    # ----------
    st.subheader("ğŸ’¼ ä¿æœ‰æ ªä¸€è¦§")

    display_cols = ["ã‚³ãƒ¼ãƒ‰", "éŠ˜æŸ„å", "æ ªä¾¡", "PER", "PBR", "ROE(%)",
                    "å–å¾—å˜ä¾¡", "æšæ•°", "æ™‚ä¾¡", "æç›Š", "ãƒ«ãƒƒã‚¯ã‚¹ãƒ«ãƒ¼åˆ©ç›Š"]
    view_holding = holding_df[display_cols].copy()
    for col in ["æ ªä¾¡", "PER", "PBR", "ROE(%)"]:
        view_holding[col] = pd.to_numeric(view_holding[col], errors="coerce").round(1)
    view_holding["å–å¾—å˜ä¾¡"] = view_holding["å–å¾—å˜ä¾¡"].round(0)
    view_holding["æ™‚ä¾¡"]     = view_holding["æ™‚ä¾¡"].round(0)
    view_holding["æç›Š"]     = view_holding["æç›Š"].round(0)
    view_holding["ãƒ«ãƒƒã‚¯ã‚¹ãƒ«ãƒ¼åˆ©ç›Š"] = view_holding["ãƒ«ãƒƒã‚¯ã‚¹ãƒ«ãƒ¼åˆ©ç›Š"].round(0)

    edited_holding = st.data_editor(
        view_holding, use_container_width=True,
        column_config={
            "å–å¾—å˜ä¾¡": st.column_config.NumberColumn(format="Â¥%.0f"),
            "æšæ•°":     st.column_config.NumberColumn(),
            "æ™‚ä¾¡":     st.column_config.NumberColumn(format="Â¥%.0f", disabled=True),
            "æç›Š":     st.column_config.NumberColumn(format="Â¥%.0f", disabled=True),
            "ãƒ«ãƒƒã‚¯ã‚¹ãƒ«ãƒ¼åˆ©ç›Š": st.column_config.NumberColumn(format="Â¥%.0f", disabled=True),
        },
        num_rows="dynamic"
    )

    if st.button("ä¿æœ‰æ ªã‚’ä¿å­˜"):
        save_holding = edited_holding[["ã‚³ãƒ¼ãƒ‰", "éŠ˜æŸ„å", "å–å¾—å˜ä¾¡", "æšæ•°"]].copy()
        save_holding["ã‚³ãƒ¼ãƒ‰"] = save_holding["ã‚³ãƒ¼ãƒ‰"].apply(normalize_code)
        save_df(holding_sheet, save_holding)
        st.success("ä¿å­˜ã—ã¾ã—ãŸ")
        st.rerun()

    st.divider()

    # ----------
    # ç·è³‡ç”£ã‚°ãƒ©ãƒ•
    # ----------
    st.subheader("ğŸ“ˆ ç·è³‡ç”£æ¨ç§»")

    if len(history_df) > 0:
        history_df["æ—¥ä»˜"]   = pd.to_datetime(history_df["æ—¥ä»˜"])
        history_df["ç·è³‡ç”£"] = pd.to_numeric(history_df["ç·è³‡ç”£"], errors="coerce")
        history_df["æç›Šåˆè¨ˆ"] = pd.to_numeric(history_df["æç›Šåˆè¨ˆ"], errors="coerce")

        # æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        min_date = history_df["æ—¥ä»˜"].min().date()
        max_date = history_df["æ—¥ä»˜"].max().date()
        col_a, col_b = st.columns(2)
        with col_a:
            start_date = st.date_input("é–‹å§‹æ—¥", value=min_date, min_value=min_date, max_value=max_date)
        with col_b:
            end_date   = st.date_input("çµ‚äº†æ—¥", value=max_date, min_value=min_date, max_value=max_date)

        filtered = history_df[
            (history_df["æ—¥ä»˜"].dt.date >= start_date) &
            (history_df["æ—¥ä»˜"].dt.date <= end_date)
        ].sort_values("æ—¥ä»˜")

        if len(filtered) > 0:
            st.line_chart(filtered.set_index("æ—¥ä»˜")[["ç·è³‡ç”£", "æç›Šåˆè¨ˆ"]])
        else:
            st.info("æŒ‡å®šæœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
    else:
        st.info("ã¾ã è¨˜éŒ²ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ä¿æœ‰æ ªã‚’ç™»éŒ²ã™ã‚‹ã¨ã‚¢ãƒ—ãƒªã‚’é–‹ããŸã³ã«è‡ªå‹•è¨˜éŒ²ã•ã‚Œã¾ã™ã€‚")
